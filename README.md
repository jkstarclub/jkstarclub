# John Kim

I am AeroReady âœ¨
[Convocation](https://youtu.be/OpY1wS1aBok)
[PDF](https://issuu.com/bcit/docs/4488_convo_digital_program_isuu/32)

Also, NFL ready ::
[Click here to](https://jkstarclub.github.io/JKSTARCLUB/) Ruby Slides & <br />
ssh -N -f -L localhost:8889:localhost:8889 user@jupyter-ip-address

# The Bayesian Frequentist

1) The frequentist can be considered objective when we want to forecast the outcome of individually connected ecosystem. We can predict the movement of the stars because they are connected and synchronous. The Bayesian is considered objective when the subjects have an absolute belief. We can forecast whatever event will occur based on their absolute belief. For example, if a micro appointed assembly knows someone has a strong belief than the others, that someone does not belong to an event of whatever is not special being to be vice versa. <br>
2) The frequentist fails when the subject is too large or too small to be connected in one dimension. The Bayesian fails when the subject is human. <br>
3) When the subject is a dot. The frequentist can successfully assume that it will explode. The Bayesian would say it is just one dollar. And 1 + 1 regardless of your belief.

# Universe is forever and temporary

explore wires <br />
exploit waves <br />
all about & nothing about <br/>
static frequency <br />
your web <br />
our web <br />
my escape <br />
here, ribbon <br />
Build and execute the multiverse

# Welcome to GitHub

I have seen Git or GitHub before. <br />
I can use basic functions like branching, committing changes, and merging with other repositories. <br />
I can use more advanced functions designed for collaborating with others and managing changes to source code. <br />
I use Git and GitHub regularly in my day to day work. <br />

l have seen this language before.

I am learning the basics like variables, conditionals, arithmetic, basic syntax, and string manipulation.

I can read other peoples code. I can find and fix simple bugs.

I can break down problems and prepared to reuse existing code, while implementing new functions/classes of my own and specialized libraries. I can trace the execution of most programs with ease.

I can manufacture lean, well structured code to solve complex problems utilizing the full extent of the language's feature set.

We shall do all that.

ðŸ‘‹ðŸ”­ðŸŒ±ðŸ‘¯ðŸ¤”ðŸ’¬ðŸ“«ðŸ˜„âš¡


## Lean The Opal âš¡

Here, goods and services:

1. AM32 - Three innovation and two invention before the cereal
    https://github.com/AlkaMotors/AM32-MultiRotor-ESC-firmware/
2. Programming Microcontrollers
    STM32F7508-DISCOVERY
    STM32L4R9I-EVAL
3. The Castle
    https://antofthy.gitlab.io/


## System Requirements âš¡

CMake 3.17: https://cmake.org/download/
MSVC v142: https://visualstudio.microsoft.com/visual-cpp-build-tools/

```

feat. micro refinements

In a few days, you will be able to:

 - package content
 - build process
 - refine components
 - do asset management
 - let style control

If there is a track, curve the turn like so: 

Revolve: #123

```

# The Red Dice Probability Theorem

Have you previously seen probability notation?
Have you ever seen the basic rule of probability?
For the reference, we review those here.

Probabilities are defined for events. An event is some outcome that
we could potentially observe or experience, such as
the result of rolling a fair six-sided die.

(English grammar note: die is singular, dice is plural.)

In mathematical notation, we often write an event as a capital letter,

for example, $ {A} $ is the event that we roll a $ {4} $
on a fair six-sided die. This event has probability $ {1/6} $,
so we would write $ P({A}) = {1}/{6} $.

We might want to represent the numerical result of the die roll
as the random variable ${X}$, and then we could also write
$ P({X=4}) = {1}/{6} $.

\section{Rule of Probability}
\begin{equation}
\sum^{6}_{i=1} P({X=i}) = 1.
\end{equation}
Probabilities must be between zero and one, i.e.,
$ 0 \leq P({A}) \leq {1} $
\\[.1in]
The symbol $\sum^{6}_{i=1}$ denotes adding up the entries as i goes from 1 to 6.
\\[.1in]
If there is no gravity, $ \sum^{6}_{i=1} P({X=i}) = 0 $.

In the careful dice observation, $ P({X=4}) $ must be:
{0}, Between, and {2}.

The Red Dice Theorem must result between {0} and {2} except {1}.

There is the dot but no dot.

Motion Model: \\ $ {X_k} = f({X}_{k-1}, {u}_{k}) + {W_k} $ \\
Observation Model: \\ $ {Z_k} = {h}({X_k}) + {V_k} $ \\
Initialization: \\ $ \hat{x_0} = {x_0} $, and $ {P}_{0} = {P}_{init} $. \\
Prediction: \\ $\hat{x}_{k,k-1} = {f}(\hat{x}_{k-1},{u}_{k}).$ \\
The predicted covariance: \\ ${P}_{k,k-1} = \nabla{f}{P}_{k-1}\nabla{f}^{T}+{Q}_{k}$ \\
The predicted observation value at time k: \\ $\hat{z}_{k,k-1} = {h}(\hat{x}_{k,k-1})$ \\
Observation-Update: \\ $[\hat{x}_{k}] = [\hat{x}_{k,k-1}] + K[{z}_{k} - h(\hat{x}_{k,k-1})]$, \\
${P}_{k} = {P}_{k,k-1} - {K}{S}_{k}{K}^{T}$ \\
where: \\
${S}_{k}$ \\
${K}$ \\
where $\nabla{h}$ is Jacobian Matrix. ${RV}_{k}$ The Covariance\\

${SIFT}{SURF}{HOG}{HoughTransform}{RANSAC}{KalmanFilter}{KF}{EKF}{UKF}{PointCloudLibrary}{ParticleAlgorithm}{Voxels}$
${Scale Invariant Feature Transform}$
the scale space of images and extract the local extrema with Difference of Gaussian function
${Speeded Up RobuFeatures}$
the eterminant of Hessian blob detector / Euclidean distance
${Histogram of Oriented Gradients}$
feature extraction in local region by tracking orientation histograms of edge intensity
${random Hog LPB SURF BRIEF VLC SIFT}{VLC+LBP}$
Hough transform feature extraction technique
${Random Sample Consensus}$
an iterative method to estimate parameters of a mathematical model from a set of observed data that contains outliers / the goal is to determine the points in the space that project onto an image into a set of landmarks with known locations

# Kalman Filter Family The Opal
MEKF 'Car Park Dataset' 'Victoria Park Dataset' non linear SLAM.
EKF The predicted observation value at time k is formulated like so where h is Jacobian matrix . R is the covariance of V.
UKF a set of weighted sigma points are used to represent the stochastic characteristics of the state vector.
IKF Iterated Kalman Filter
Mean Slope

$ P(A \cup B) = P(A) + P(B) - P(A \cap B) $

There must be another cookie. (And how many)

